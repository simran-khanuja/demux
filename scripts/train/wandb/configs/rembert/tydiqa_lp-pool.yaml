program: ./src/train_al.py
method: grid
parameters:
  project_name:
    value: "AL_sweep"
  target_config_name:
    value: "target_lp-pool"
  num_train_epochs:
    value: 3
  learning_rate:
    value: 1e-5
  source_languages:
    value: "id,fi,te,ar,ru"
  target_languages:
    value: "sw,bn,ko"
  dataset_name:
    value: "tydiqa"
  model_name_or_path:
    value: "./outputs/models/rembert_en-ft_squad_v2"
  output_dir:
    value: "./outputs/models"
  pred_output_dir:
    value: "./outputs/predictions"
  save_dataset_path:
    value: "./outputs/selected_data"
  save_embeddings_path:
    value: "./outputs/embeddings"
  seed:
    value: 42
  do_train:
    value: true
  do_predict:
    value: true
  pad_to_max_length:
    value: true
  per_device_train_batch_size:
    value: 32
  per_device_eval_batch_size:
    value: 32
  gradient_accumulation_steps:
    value: 1
  inference_batch_size:
    value: 512
  max_seq_length:
    value: 256
  qa_uncertainty_method:
    value: "logits"
  report_to:
    value: "wandb"
  with_tracking:
    value: true
  max_to_keep:
    value: 1
  total_rounds:
    value: 5
  save_predictions:
    value: true
  budget:
    value: "5000"
  strategy:
    values: ["random", "egalitarian", "gold_sw_bn_ko", "average_dist", "knn_uncertainty_k_1", "uncertainty"]
  embedding_model:
    value: "rembert"
  save_embeddings:
    value: true
